The results above are for 2 separate runs over the datasets one with 35 attrbutes and another with 16 attributes. Out of the initial 41 attributes, we came across 6 attributes which had no variation at all ie all their values were same for all the instances, and as a result those attributes were removed from the dataset resulting in the 35 atribute dataset. Later, after running a calculation check over this dataset we tried to find out the columns which have more than 1% variance as compared to other attributes and this is when we narrowed it down to a 16 attributes dataset. Apart from the number of attributes in each of these datasets, they are similar in all other respects and so is the structure of the results of the scripts over them.
Now, lets go through the outputs shown above to understand them better. The very first Misuse Detection talks about the Attack type Neptune. The output is expressed in the form of a confusion matrix, memory consumption by the Neural Network, Test accuracy and Execution time. Confusion Matrix is a square matrix which explains in this case, how many Neptune attacks were classified as Neptune(49) and how many were classified as Others(13) by mistake. Similarly, the next row shows how many Other attacks were classified as Neptune(3) by mistake and how many were correctly classified as Others(835). Based on the confusion matrix we calculate the other terms such as Test accuracy, False Positives and False Negatives.
Test Accuracy - Sum of the figures in the matrix diagonal divided by the sum of figures in the entire matrix. This decimal figure can actually be seen as the percent ie 0.982 ~ 98.2%
False Positives - Other attacks incorrectly classified as Neptune.(in this case 13)
False Negative - Neptune attacks incorrectly classified as Others.(in this case 3)
